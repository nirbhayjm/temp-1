[JOB_PARAMS]
algo = ['a2c']
; algo = ['ppo']
; model = ['cond']
model = ['hier']
spawn_curriculum = ['center']
; flow_type = ['none']
flow_type = ['iaf']
; flow_type = ['planar']
num_flows = [4]
use_max_ent = [1]
; traj_encoder_input = ['final_and_initial_state']
traj_encoder_input = ['final_state']
; closed_loop = [0]
hr_model_kl_coeff = [1e-3]
; hr_model_kl_coeff = [0]
q_start_epochs = [65]
; hr_model_kl_coeff = [1.0]
kl_anneal_start_epochs = [50]
kl_anneal_growth_epochs = [15]
hr_goal_encoder_type = ['single']
; reward_type = ['dense_l1_xpe']
reward_type = ['dense_l2']
spike_value = [0]
terminal_reward  = [0]
num_processes = [8]
num_agents = [8]
max_val_envs = [2]
ppo_version = ['default']
; ppo_version = ['ppo-with-options']
val_interval = [10]
skip_eval = [1]
recurrent_policy = [0]
test_recall = [0]
max_train_envs = [0]
max_targets_per_env = [0]
; options_decoder_input = ['goal_and_initial_state']
options_decoder_input = ['goal_only']
attr_embed_size = [16]
hidden_size = [32]
omega_option_dims = [10]
; DEBUG
; omega_option_dims = [2]
splits_dir = ["../splits/v2/train-50"]
; ac_start_from = ['checkpoints/a2c_start.vd']
; ac_start_from = ['checkpoints/iaf_ckpt.vd']
ac_start_from = ['']
log-interval = [10]

[SCRIPT_PARAMS]
run_file = "train.py"
wait = True
redirect_stdout = False
slurm_queue_type = "noslurm"
common_save_subdir = False
; visdom_env_name = "debug-vgc-cond-2"
; visdom_env_name = "debug-omega-two"
; visdom_env_name = "debug-omega-two-cond"
; visdom_env_name = "debug-flows-4-iaf-short-continue"
visdom_env_name = "debug"
; visdom_env_name = "debug-val-detach_vcp"
; visdom_env_name = "debug-ppo-options-control"
; visdom_env_name = "debug-closed-loop-f-plus-i-ppo-default"
