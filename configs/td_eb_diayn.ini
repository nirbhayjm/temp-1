[JOB_PARAMS]

; Environment hyperparams
; 'randomtwo' , 'corridor', 'multiroom']
; env_name = ['empty-pomdp', 'two-room-corridor-pomdp']
; env_name = ['four-rooms-pomdp', 'maze-pomdp']
; env_name = ['empty-pomdp', 'two-room-corridor-pomdp', 'four-rooms-pomdp', 'maze-pomdp']
; env_name = ['maze-pomdp']
; env_name = ['four-rooms-pomdp']
env_name = ['multiroom']
; config_seed = [18, 37]
config_seed = [18]
obs_win_size = [1]
corridor_len = [3]
agent_view_size = [3]
spawn_curriculum = ['fixed']
reset_adaptive = [0]
perturb_prob = [0.0]
reset_prob = [1.0]
term_prob = [1e-4]
end_on_goal = [1]
; recurrent_policy = [0, 1]
; recurrent_encoder = [0, 1]
recurrent_policy = [1]
recurrent_encoder = [1]
reward_scale = [30]
use_td = [1]
critic_detach = [0]

; Multiroom hyperparams
env_grid_size = [4]
; env_grid_size = [25]
multiroom_doors_open = [0]
multiroom_num_rooms = [3]
; multiroom_num_rooms = [6]
num_steps = [5]
; num_steps = [100]
; num_steps = [250]
num_eval_episodes = [256]

; Bonus params
hier_mode = ['bonus']

bonus_beta = [1.0, 0.5, 0.1, 5e-2, 1e-2]
; bonus_beta = [0.1]

bonus_heuristic_beta = [-1]
; bonus_type = ['kl']
bonus_type = ['kl-pi']
bonus_normalization = ['unnormalized']

; Maze hyperparams
; maze_complexity = [0.025]
maze_complexity = [0.4]
maze_density = [0.99]
static_env_grid = [0]

; Legacy hyperparams, do not change
algo = ['a2c']
; model = ['hier']
model = ['cond']
hr_goal_encoder_type = ['single']
; hr_goal_encoder_type = ['poe']

; Intrinsic Control (IC) hyperparams
ic_mode = ['vic']
; ic_mode = ['diyan']
; ic_mode = ['vic', 'diyan', 'valor']
; option_space = ['continuous']
option_space = ['discrete']
omega_option_dims = [32]
; omega_option_dims = [4]
use_omega_dim_curriculum = [1]
omega_curr_win_size = [200]
omega_traj_ll_theta = [0.75]
reweight_by_omega_ll = [0]

; Information Bottleneck (IB) hyperparams
use_infobot = [0]
; infobot_beta = [0.0]
infobot_beta = [1e-3]
infobot_beta_min = [1e-6]
infobot_beta_curriculum = ['auto-10-250']
ib_adaptive = [0]
z_latent_dims = [128]
z_stochastic = [1]
ib_kl_mode = ['analytic']

; Miscellaneous IC Hyperparams
kl_optim_mode = ['mc_sampling']
hr_model_kl_coeff = [1.0]
q_start_epochs = [0]
kl_anneal_start_epochs = [0]
kl_anneal_growth_epochs = [0]

; Max-entropy / entropy-reg Hyperparams
use_max_ent = [1]
; entropy-coef = [0]
entropy-coef = [0.01]
max_ent_action_logprob_coeff = [1e-3]

; Everything else
base_model = ['mlp']
normalize_advantage = [1]
traj_encoder_input = ['final_and_initial_state']
traj_enc_loss_coeff = [1.0]
num_agents = [1]
num_processes = [64]
grid_obs_type = ['grid']
hidden_size = [128]
attr_embed_size = [128]
lr = [7e-4]
gamma = [0.99]
save-interval = [1]

; -- After errata fix --
; N2S6


; N2S10
; 

ac_start_from = ['']
log-interval = [5]
; log-interval = [20]
heatmap-interval = [100]
val_interval = [25000]
; val_interval = [500000]
num-episodes = [1.28e7]
; seed = [3120, 3121, 3122, 3123, 3124, 128, 42, 2048, 1155, 2277]
; seed = [128, 42, 2048, 1155, 2277]
; seed = [420, 696969, 333]
seed = [420]
; seed = [420, 696969, 333, 3120, 3121, 3122, 3123, 3124, 128, 4271]
; seed = [3123, 3124, 128, 4271]
; seed = [3120, 3121, 3122, 3123, 3124, 128, 4271]
; seed = [5193]

[SCRIPT_PARAMS]
run_file = "train_minigrid.py"
; run_id = "TD-EBD-2.0-N{multiroom_num_rooms}S{env_grid_size}-{bonus_type}-3x"
run_id = "TD-EBD-2.0-N{multiroom_num_rooms}S{env_grid_size}-{bonus_type}-kappa"
; run_id = "TD-EB-1.2-N6S25-kappa-VIC=1e-9-epzero"
; run_id = "EB-6.3-10x-count-n250"
common_save_subdir = True
redirect_stdout = True
wait = False
; slurm_queue_type = "noslurm"
slurm_queue_type = "short"
qos_overcap = False
visdom_env_name = None
; time_limit = 2
time_limit = 1
; time_limit = 12

dry_run = True
