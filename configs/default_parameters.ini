[JOB_PARAMS]
; All values must be in a python list
env_name = ['onecorner']
static_env_grid = [1]
env_grid_size = [5]
agent_view_size = [7]
term_prob = [0.0]
model = ['cond']
hier_mode = ['default']
ic_mode  = ['vic']
obs_win_size = [1]
end_on_goal = [0]
replan_strategy = ['constant']
reset_adaptive = [0]
multiroom_num_rooms = [2]
multiroom_doors_open = [0]
flow_type = ['none']
num_flows = [5]
bonus_beta = [1]
bonus_heuristic_beta = [0.0]
total_training_steps = [10e10]
bonus_type = ['count']
bonus_normalization = ['unnormalized']
bonus_noise_scale = [0.0]
z_std_clip_max = [2]
train_split = ['train.json']
num_eval_episodes = [128]
reward_scale = [1.0]
randomize_goal_pos = [1]
reward_type = ['dense_l2']
reset_prob = [1.0]
perturb_prob = [0.0]
potential_type = ['l1']
closed_loop = [1]
terminal_reward  = [0]
z_stochastic = [1]
spike_value = [0]
num_processes = [16]
critic_detach = [1]
use_infobot = [1]
num_agents = [8]
use_td = [0]
algo = ['ppo']
; gamma = [0.97]
gamma = [0.99]
lr = [2.5e-4]
ppo_version = ['default']
clip_param = [0.1]
omega_curr_win_size = [200]
omega_traj_ll_theta = [0.86]
traj_enc_loss_coeff = [1.0]
reweight_by_omega_ll = [0]
max_train_envs = [0]
max_targets_per_env = [0]
max_val_envs = [0]
base_model = ['cnn-mlp']
grid_obs_type = ['grid']
corridor_len = [1]
use_max_ent = [0]
max_ent_action_logprob_coeff = [0.001]
infobot_beta = [0.0]
infobot_beta_curriculum = ['0-0']
use_omega_dim_curriculum = [0]
z_latent_dims = [32]
recurrent_policy = [0]
recurrent_encoder = [0]
allow_early_stop = [1]
use_pretrained_encoder = [0]
hidden_size = [128]
normalize_advantage = [0]
entropy-coef = [0.01]
infobot_beta_min = [1e-6]
ib_adaptive = [0]
target_embed_type = ['k-hot']
traj_encoder_input = ['final_and_initial_state']
options_decoder_input = ['goal_and_initial_state']
kl_optim_mode = ['analytic']
ib_kl_mode = ['analytic']
hr_goal_encoder_type = ['single']
spawn_curriculum = ['random']
option_space = ['continuous']
omega_option_dims = [50]
hr_model_kl_coeff = [0.0]
kl_anneal_start_epochs = [100]
kl_anneal_growth_epochs = [100]
maze_complexity = [0.9]
maze_density = [0.9]
save-interval = [10]
heatmap-interval = [10]
log-interval = [10]
val_interval = [100000]
skip_eval = [0]
num_steps = [50]
num_option_steps = [10]
server = ['localhost']
; server = ['devfair0326']
; port = [8893]
port = [8896]
log-dir = ['logs/']
save-dir = ['checkpoints/']
train_reachability_threshold = [1]
use-gae = [1]
attr_embed_size = [16]
test_recall = [0]
vis_heatmap = [1]

ac_start_from = ['']

q_start_epochs = [0]
num-episodes = [3e6]
splits_dir = ["../splits/v2/train-50"]
seed = [123]
config_seed = [13]

[SCRIPT_PARAMS]

; Identifier for the run script instance, useful for identifying
; all jobs belonging to the same hyperparameter sweep
run_id = "default"

; The training file to run the job
run_file = "train_minigrid.py"

; If True, all checkpoint sub-dirs across all jobs will
; have a common prefix == run_id and an integer suffix indicating the
; index of the job in the hyperparameter sweep.
; If False, a randomly generated sub-dir name is used for all jobs.
common_save_subdir = False

; Whether to wait i.e. block while a job is running. Use wait -> True
; for debugging, else keep it False.
wait = False

; Whether to pipe stdout to cmd or to a log file
redirect_stdout = True

; Slurm queue type, either "debug", "short", "long" or "noslurm"
; where the first three are SLURM queue types and "noslurm" just
; runs the command directly without using SLURM. Use "noslurm"
; when in an interactive slurm debug queue.
slurm_queue_type = "debug"

; If visdom_env_name is None, automatically generated name is used.
; For single debug jobs, a custom name is recommended in which
; case visdom_env_name should be set to a string value.
; For hyperparameter sweeps, it is advisabvle to use automatically
; generated visdom environment names.
visdom_env_name = None

; Whether to use --qos=overcap to allow overcap queue. Jobs may be
; pre-empted in this qos type.
qos_overcap = False

; Do a dry run of run.py without launching jobs
dry_run = False

; Whether to run job as "CUDA_LAUNCH_BLOCKING=1 python ..."
cuda_launch_blocking = False

; Auto xvfb display, for rendering gym environments
xvfb_display = False

; Custom time limit for job
time_limit = 0





; slurm's --exclude node-list

