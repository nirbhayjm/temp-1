[JOB_PARAMS]
; env_name = ['twogoals']
; env_name = ['randomtwo']
; env_name = ['two-room-corridor']
; env_name = ['four-rooms']
; env_name = ['pillar-grid']
; env_name = ['crossing']
; env_name = ['maze']
; env_name = ['empty-pomdp']
; env_name = ['two-room-corridor-pomdp']
; env_name = ['four-rooms-pomdp']
; env_name = ['maze-pomdp']
env_name = ['multiroom']
static_env_grid = [0]
obs_win_size = [1]
end_on_goal = [1]
config_seed = [18]
; config_seed = [37]
agent_view_size = [3]
corridor_len = [3]
; spawn_curriculum = ['center']
spawn_curriculum = ['fixed']
; spawn_curriculum = ['random']
reset_prob = [1.0]
perturb_prob = [0.0]
reset_adaptive = [0]
term_prob = [1e-4]
recurrent_policy = [1]
recurrent_encoder = [1]
num_option_steps = [8]
replan_strategy = ['constant']
; reward_scale = [1]
reward_scale = [30]
use_td = [1]
critic_detach = [0]

; Maze hyperparams
; ; maze_complexity = [0.025]
; maze_complexity = [0.4]
; maze_density = [0.99]
maze_complexity = [0.05]
maze_density = [0.2]

; Multiroom hyperparams
multiroom_doors_open = [0]
; multiroom_num_rooms = [3]
; multiroom_num_rooms = [5]
multiroom_num_rooms = [6]
; multiroom_num_rooms = [1]
; env_grid_size = [8]
; env_grid_size = [4]
env_grid_size = [25]
num_steps = [5]
; num_steps = [60]
; num_steps = [80]
; num_steps = [5]
; num_steps = [100]
; num_steps = [25]
num_eval_episodes = [128]
; num_eval_episodes = [512]

model = ['cond']
; model = ['hier']

; hier_mode = ['default']
; hier_mode = ['vic']
; hier_mode = ['transfer']
hier_mode = ['bonus']
; bonus_beta = [0.02333]
; bonus_beta = [0.05789]
; bonus_beta = [0.1]
; bonus_beta = [0.1]
; bonus_beta = [0.0]
; bonus_beta = [1.0]
; bonus_heuristic_beta = [10.0]
bonus_heuristic_beta = [0]
; bonus_heuristic_beta = [0.1]
; bonus_beta = [0.00386]
; bonus_beta = [1e-3]
; bonus_beta = [1e-2]
bonus_beta = [0.005]
; bonus_beta = [1e-5]
; bonus_beta = [1]
; bonus_beta = [0]
; bonus_type = ['count']
bonus_type = ['kl']
; bonus_type = ['kl-pi']
bonus_normalization = ['unnormalized']
; bonus_normalization = ['max_min']
bonus_noise_scale = [0.0]
; bonus_noise_scale = [0.001788]
; bonus_noise_scale = [0.0075]
; bonus_noise_scale = [0.00875]

ic_mode = ['vic']
; ic_mode = ['diyan']
; ic_mode = ['valor']
; option_space = ['continuous']
option_space = ['discrete']
omega_option_dims = [32]
use_omega_dim_curriculum = [1]
omega_curr_win_size = [200]
omega_traj_ll_theta = [0.75]
reweight_by_omega_ll = [0]
; omega_option_dims = [32]

use_infobot = [0]
z_stochastic = [1]
; infobot_beta = [0]
infobot_beta = [1e-3]
infobot_beta_min = [1e-6]
infobot_beta_curriculum = ['auto-10-250']
; infobot_beta_curriculum = ['0-0']
ib_adaptive = [0]
ib_kl_mode = ['analytic']
z_latent_dims = [128]

; use_max_ent = [0]
use_max_ent = [1]
; entropy-coef = [0.01]
; max_ent_action_logprob_coeff = [0.0]
; max_ent_action_logprob_coeff = [1]
max_ent_action_logprob_coeff = [1e-3]

hr_model_kl_coeff = [1.0]
; hr_model_kl_coeff = [1e-3]
; hr_model_kl_coeff = [0]

q_start_epochs = [0]
; kl_optim_mode = ['analytic']
kl_optim_mode = ['mc_sampling']
kl_anneal_start_epochs = [0]
kl_anneal_growth_epochs = [0]

algo = ['a2c']
gamma = [0.99]
normalize_advantage = [1]

; lr = [1e-4] # Too less but converges
; lr = [2.5e-4] # Converges with same rate as 1e-4
lr = [7e-4]
; lr = [0.001] # Too high, didn't converge
traj_enc_loss_coeff = [1.0]

; base_model = ['cnn-mlp']
base_model = ['mlp']

z_std_clip_max = [2]
hr_goal_encoder_type = ['single']
grid_obs_type = ['grid']
spike_value = [0]
terminal_reward  = [0]
num_processes = [64]
; num_processes = [2]
num_agents = [1]
max_val_envs = [2]
ppo_version = ['default']
; ppo_version = ['ppo-with-options']
skip_eval = [0]
test_recall = [0]
max_train_envs = [0]
max_targets_per_env = [0]
save-interval = [10000]
; save-interval = [20]

options_decoder_input = ['goal_and_initial_state']
; options_decoder_input = ['goal_only']

traj_encoder_input = ['final_and_initial_state']
; traj_encoder_input = ['final_state']

; attr_embed_size = [16]
attr_embed_size = [128]
hidden_size = [128]
; hidden_size = [64]

; splits_dir = ["../splits/v2/train-50"]
; ac_start_from = ['checkpoints/a2c_start.vd']
; ac_start_from = ['checkpoints/iaf_ckpt.vd']
; ac_start_from = ['checkpoints/cond-ss.vd']
; ac_start_from = ['checkpoints/ckpt_vic_ib_corridor.vd']
; ac_start_from = ['checkpoints/IC-IB-2.6.2tr_02-Apr-2019-17-28-00_4309241_1/a2c_0700.vd']
; ac_start_from = ['checkpoints/15-Apr-2019-15-39-58_5803525/a2c_0260.vd']
; ac_start_from = ['checkpoints/29-Apr-2019-18-58-38_7641388/a2c_0000.vd']
; ac_start_from = ['checkpoints/TARL-1.5p_30-Apr-2019-17-31-23_3720593_3/a2c_0300.vd']
ac_start_from = ['']

; 
; 
; Maze W=2 (intersections):
; 

; Four-room W=4
; 

; Empty room W=2
; 

; Control Empty room W=2
; 

; Multiroom W=1, agent_view_size=3
; 

; Multiroom W=2, N2S10
; 

; Multiroom W=2 debug N2S6
; 

; Multiroom W=2 N2S6
; 

; 15x15 maze W=1
; 

; Diyan baseline
; 

; 4-rooms W=1
; 

; VIC on N2S10 W=1
; 

; DIYAN baseline N2S10 W=1
; 

; Infobot-supervised
; 
; N2S6
; 

; Infobot loose bottleneck on N2S10 with \beta=0.00005
; 

; Infobot new recurrence
; 

; VIC debug
; 

; VIC 1e-9 debug ckpt
; 
; VIC 1e-9 0-epoch ckpt
; 

; VIC 1e-3
; 

; -- ICLR Submission IBS ---
; Trained on N2S10
; 

; Trained on N2S10, beta=0.005
; 

; -- NeurIPS Rebuttal
; Static = 1
; 

; Static = 0
; 
; Static 0, last ditch effort
; 
; -- ICLR Submission IBS ---



; heatmap-interval = [400]
; log-interval = [400]
heatmap-interval = [20]
log-interval = [5]
; log-interval = [20]
; val_interval = [25000]
val_interval = [9999999999]
; val_interval = [100000]
num-episodes = [3.5e8]
; total_training_steps = [100000]
total_training_steps = [99999999999]
; server = ['localhost']
; port = [8895]
; log-interval = [1]
; seed = [5193]
; seed = [430]
seed = [128]

[SCRIPT_PARAMS]
run_file = "train_minigrid.py"
wait = True
redirect_stdout = False
slurm_queue_type = "noslurm"
common_save_subdir = False
; 

; visdom_env_name = "debug-diyan-4-r0"
; visdom_env_name = "debug-transfer-cor-1"
; visdom_env_name = "debug-pomdp-new-1"
; visdom_env_name = "debug-pomdp-bonus-15-kl-nr5-rc30-2"
; visdom_env_name = "debug-pomdp-bonus-16-kl-nr3"
; visdom_env_name = "debug-pomdp-bonus-19-kl-fourrooms"
; visdom_env_name = "debug-pomdp-bonus-21-count"
; visdom_env_name = "debug-supervised-ib-bonus-2"
; visdom_env_name = "debug-supervised-ib-bonus-3-loose"
; visdom_env_name = "debug-supervised-ib-new-r-3"
; visdom_env_name = "debug-maze-bonus-1-control"
; visdom_env_name = "debug-maze-bonus-3"
; visdom_env_name = "debug-multiroom-n12"
; visdom_env_name = "debug-count-variance-2"
; visdom_env_name = "debug-count-variance-kl-zero-epoch"
; visdom_env_name = "debug-kl-td-3"
visdom_env_name = "debug-ibs-small-2"
; visdom_env_name = "debug-vis"
cuda_launch_blocking = False
